{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef54c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5772b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyarrow as pa\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, DataCollatorForLanguageModeling\n",
    "import modules.tweet_helper as tweet_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52c41166",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./generate_replies_model_new_2\"\n",
    "finetuned_model_name = \"gpt2-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69927c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE AND FILTER THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9b0172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_df = pd.read_csv(\"op.csv\")\n",
    "op_df = op_df.drop_duplicates(subset=\"op_id\", keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c52f7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "replies_df = pd.read_csv(\"replies.csv\")\n",
    "replies_df = replies_df.drop_duplicates(subset=\"reply_id\", keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d5761e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>like_count_x</th>\n",
       "      <th>reply_count_x</th>\n",
       "      <th>quote_count_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>like_count_y</th>\n",
       "      <th>reply_count_y</th>\n",
       "      <th>quote_count_y</th>\n",
       "      <th>text_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1597824424505651203</td>\n",
       "      <td>1597824964648120320</td>\n",
       "      <td>2022-11-30T05:28:52.000Z</td>\n",
       "      <td>606987031</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Representing BCDA in the turnover of facilitie...</td>\n",
       "      <td>2022-11-30T05:26:43.000Z</td>\n",
       "      <td>606987031</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Leading the event is Acting Chief of Staff MGe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1597774607259312129</td>\n",
       "      <td>1597825062547050496</td>\n",
       "      <td>2022-11-30T05:29:15.000Z</td>\n",
       "      <td>35877816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@WalshFreedom Jack The Ripper: \"I believe in a...</td>\n",
       "      <td>2022-11-30T02:08:46.000Z</td>\n",
       "      <td>236487888</td>\n",
       "      <td>3114</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>Bullshit. The leader of your party is a crimin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1597774607259312129</td>\n",
       "      <td>1597776539957231616</td>\n",
       "      <td>2022-11-30T02:16:27.000Z</td>\n",
       "      <td>1419231540609884162</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@WalshFreedom DemocRat Joey is wrong again 👉🤡 ...</td>\n",
       "      <td>2022-11-30T02:08:46.000Z</td>\n",
       "      <td>236487888</td>\n",
       "      <td>3114</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>Bullshit. The leader of your party is a crimin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1597825638630854656</td>\n",
       "      <td>1597825646310588416</td>\n",
       "      <td>2022-11-30T05:31:34.000Z</td>\n",
       "      <td>766540464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks for reading this week's #WallaWarriors ...</td>\n",
       "      <td>2022-11-30T05:31:33.000Z</td>\n",
       "      <td>766540464</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Great job, Monica!  Nice that you've got your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1597571148501458944</td>\n",
       "      <td>1597824240497364992</td>\n",
       "      <td>2022-11-30T05:25:59.000Z</td>\n",
       "      <td>1593332431276412929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@D__Barbie @THE_FREE_COIN @Freecoin_global @Ma...</td>\n",
       "      <td>2022-11-29T12:40:17.000Z</td>\n",
       "      <td>1289211227030401030</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>$FREE 💎 up over 30% in the day. Love to see it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597061</th>\n",
       "      <td>1602043102935633922</td>\n",
       "      <td>1602058505359327232</td>\n",
       "      <td>2022-12-11T21:51:27.000Z</td>\n",
       "      <td>1596442024819015680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>That's a long time to keep refinancing your \"e...</td>\n",
       "      <td>2022-12-11T20:50:14.000Z</td>\n",
       "      <td>1596442024819015680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>People deserve the justice of knowing what som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597062</th>\n",
       "      <td>1602057915904708608</td>\n",
       "      <td>1602058547415875584</td>\n",
       "      <td>2022-12-11T21:51:37.000Z</td>\n",
       "      <td>224777045</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>If you click on the image in the story, you wi...</td>\n",
       "      <td>2022-12-11T21:49:06.000Z</td>\n",
       "      <td>224777045</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tucked inside this story is an image I made fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597063</th>\n",
       "      <td>1601795232407834624</td>\n",
       "      <td>1602058485759643648</td>\n",
       "      <td>2022-12-11T21:51:22.000Z</td>\n",
       "      <td>1569808143831691265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@gryphon_katsu Noming a naughty chimken! https...</td>\n",
       "      <td>2022-12-11T04:25:17.000Z</td>\n",
       "      <td>2787059839</td>\n",
       "      <td>77</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>show me your maws 👀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597064</th>\n",
       "      <td>1602057634567290880</td>\n",
       "      <td>1602058450737020932</td>\n",
       "      <td>2022-12-11T21:51:14.000Z</td>\n",
       "      <td>1456442895154786309</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the hyudoro got compressed to shit so heres a ...</td>\n",
       "      <td>2022-12-11T21:47:59.000Z</td>\n",
       "      <td>1456442895154786309</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>had to add one more https://t.co/bg8WtcaxNZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597065</th>\n",
       "      <td>1602038425011601408</td>\n",
       "      <td>1602058856703688705</td>\n",
       "      <td>2022-12-11T21:52:50.000Z</td>\n",
       "      <td>1559168650858348546</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@Lefty_Barbarian @Jesse_Brenneman no no, of co...</td>\n",
       "      <td>2022-12-11T20:31:39.000Z</td>\n",
       "      <td>819890495820365824</td>\n",
       "      <td>305</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@accountpalatine @Jesse_Brenneman Do you... th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597066 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      op_id             reply_id              created_at_x  \\\n",
       "0       1597824424505651203  1597824964648120320  2022-11-30T05:28:52.000Z   \n",
       "1       1597774607259312129  1597825062547050496  2022-11-30T05:29:15.000Z   \n",
       "2       1597774607259312129  1597776539957231616  2022-11-30T02:16:27.000Z   \n",
       "3       1597825638630854656  1597825646310588416  2022-11-30T05:31:34.000Z   \n",
       "4       1597571148501458944  1597824240497364992  2022-11-30T05:25:59.000Z   \n",
       "...                     ...                  ...                       ...   \n",
       "597061  1602043102935633922  1602058505359327232  2022-12-11T21:51:27.000Z   \n",
       "597062  1602057915904708608  1602058547415875584  2022-12-11T21:51:37.000Z   \n",
       "597063  1601795232407834624  1602058485759643648  2022-12-11T21:51:22.000Z   \n",
       "597064  1602057634567290880  1602058450737020932  2022-12-11T21:51:14.000Z   \n",
       "597065  1602038425011601408  1602058856703688705  2022-12-11T21:52:50.000Z   \n",
       "\n",
       "                author_id_x  like_count_x  reply_count_x  quote_count_x  \\\n",
       "0                 606987031             0              1              0   \n",
       "1                  35877816             0              0              0   \n",
       "2       1419231540609884162             1              0              0   \n",
       "3                 766540464             0              0              0   \n",
       "4       1593332431276412929             0              0              0   \n",
       "...                     ...           ...            ...            ...   \n",
       "597061  1596442024819015680             0              1              0   \n",
       "597062            224777045             9              2              0   \n",
       "597063  1569808143831691265             0              0              0   \n",
       "597064  1456442895154786309             1              1              0   \n",
       "597065  1559168650858348546            28              2              0   \n",
       "\n",
       "                                                   text_x  \\\n",
       "0       Representing BCDA in the turnover of facilitie...   \n",
       "1       @WalshFreedom Jack The Ripper: \"I believe in a...   \n",
       "2       @WalshFreedom DemocRat Joey is wrong again 👉🤡 ...   \n",
       "3       Thanks for reading this week's #WallaWarriors ...   \n",
       "4       @D__Barbie @THE_FREE_COIN @Freecoin_global @Ma...   \n",
       "...                                                   ...   \n",
       "597061  That's a long time to keep refinancing your \"e...   \n",
       "597062  If you click on the image in the story, you wi...   \n",
       "597063  @gryphon_katsu Noming a naughty chimken! https...   \n",
       "597064  the hyudoro got compressed to shit so heres a ...   \n",
       "597065  @Lefty_Barbarian @Jesse_Brenneman no no, of co...   \n",
       "\n",
       "                    created_at_y          author_id_y  like_count_y  \\\n",
       "0       2022-11-30T05:26:43.000Z            606987031             1   \n",
       "1       2022-11-30T02:08:46.000Z            236487888          3114   \n",
       "2       2022-11-30T02:08:46.000Z            236487888          3114   \n",
       "3       2022-11-30T05:31:33.000Z            766540464             0   \n",
       "4       2022-11-29T12:40:17.000Z  1289211227030401030             6   \n",
       "...                          ...                  ...           ...   \n",
       "597061  2022-12-11T20:50:14.000Z  1596442024819015680             0   \n",
       "597062  2022-12-11T21:49:06.000Z            224777045            33   \n",
       "597063  2022-12-11T04:25:17.000Z           2787059839            77   \n",
       "597064  2022-12-11T21:47:59.000Z  1456442895154786309             1   \n",
       "597065  2022-12-11T20:31:39.000Z   819890495820365824           305   \n",
       "\n",
       "        reply_count_y  quote_count_y  \\\n",
       "0                   1              0   \n",
       "1                  74             14   \n",
       "2                  74             14   \n",
       "3                   1              0   \n",
       "4                   3              0   \n",
       "...               ...            ...   \n",
       "597061              1              0   \n",
       "597062              1              0   \n",
       "597063             54              0   \n",
       "597064              1              0   \n",
       "597065              2              0   \n",
       "\n",
       "                                                   text_y  \n",
       "0       Leading the event is Acting Chief of Staff MGe...  \n",
       "1       Bullshit. The leader of your party is a crimin...  \n",
       "2       Bullshit. The leader of your party is a crimin...  \n",
       "3       Great job, Monica!  Nice that you've got your ...  \n",
       "4       $FREE 💎 up over 30% in the day. Love to see it...  \n",
       "...                                                   ...  \n",
       "597061  People deserve the justice of knowing what som...  \n",
       "597062  Tucked inside this story is an image I made fr...  \n",
       "597063                                show me your maws 👀  \n",
       "597064        had to add one more https://t.co/bg8WtcaxNZ  \n",
       "597065  @accountpalatine @Jesse_Brenneman Do you... th...  \n",
       "\n",
       "[597066 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = replies_df.merge(op_df, how='inner', on=\"op_id\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67a7b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"like_count_x\"] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3045adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy() # Otherwise will throw SettingWithCopyWarning \n",
    "df[\"text_x\"] = df[\"text_x\"].map(lambda x: tweet_helper.fix_tweet_text(x))\n",
    "df[\"text_y\"] = df[\"text_y\"].map(lambda y: tweet_helper.fix_tweet_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d34fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_row(row):\n",
    "    return not (row[\"text_x\"] == \"\" or row[\"text_y\"] == \"\" or tweet_helper.filter_tweet(row[\"text_x\"]) or tweet_helper.filter_tweet(row[\"text_y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb5fca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.apply(filter_row, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23612ee0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Refactor the dataframe to only keep the important columns\n",
    "df.rename(columns = {'text_x':'reply_text', 'text_y':'op_text'}, inplace = True)\n",
    "df = df[[\"op_id\", \"reply_id\", \"reply_text\", \"op_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b159c606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>op_text</th>\n",
       "      <th>reply_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1597416255207587841</td>\n",
       "      <td>1597623287164547073</td>\n",
       "      <td>I would love to have a sit down conversation w...</td>\n",
       "      <td>I plan to stay out of gunshot range of you, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1597416255207587841</td>\n",
       "      <td>1597602320379936770</td>\n",
       "      <td>I would love to have a sit down conversation w...</td>\n",
       "      <td>Start with the families of the two people you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1597416255207587841</td>\n",
       "      <td>1597587154255089664</td>\n",
       "      <td>I would love to have a sit down conversation w...</td>\n",
       "      <td>Cry me a river.\\nRittenhouse wasn't found \"\"in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1597416255207587841</td>\n",
       "      <td>1597520308927594496</td>\n",
       "      <td>I would love to have a sit down conversation w...</td>\n",
       "      <td>You brought an AR15 to a town and killed peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1597416255207587841</td>\n",
       "      <td>1597500162032930818</td>\n",
       "      <td>I would love to have a sit down conversation w...</td>\n",
       "      <td>You are a heroe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597047</th>\n",
       "      <td>1601970615191224323</td>\n",
       "      <td>1602058884734140416</td>\n",
       "      <td>bro's mad about fortnite skins not having any ...</td>\n",
       "      <td>Y’know the drill homes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597048</th>\n",
       "      <td>1602058829738418180</td>\n",
       "      <td>1602058837401505792</td>\n",
       "      <td>(4) being close &amp; playful together - feeling s...</td>\n",
       "      <td>(5) Gat returns home after work - Wa smells pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597051</th>\n",
       "      <td>1601999533243863044</td>\n",
       "      <td>1602058543460384770</td>\n",
       "      <td>Okok, I’ll try to watch 5 minutes 🤮</td>\n",
       "      <td>SCAM, Dont watch at all - 1 second is a hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597059</th>\n",
       "      <td>1602057744902590464</td>\n",
       "      <td>1602058540281221121</td>\n",
       "      <td>An air fryer?</td>\n",
       "      <td>why does it have a mouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597065</th>\n",
       "      <td>1602038425011601408</td>\n",
       "      <td>1602058856703688705</td>\n",
       "      <td>Do think that happened?</td>\n",
       "      <td>no no, of course but thats what Jesse appears ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322073 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      op_id             reply_id  \\\n",
       "13      1597416255207587841  1597623287164547073   \n",
       "14      1597416255207587841  1597602320379936770   \n",
       "15      1597416255207587841  1597587154255089664   \n",
       "16      1597416255207587841  1597520308927594496   \n",
       "17      1597416255207587841  1597500162032930818   \n",
       "...                     ...                  ...   \n",
       "597047  1601970615191224323  1602058884734140416   \n",
       "597048  1602058829738418180  1602058837401505792   \n",
       "597051  1601999533243863044  1602058543460384770   \n",
       "597059  1602057744902590464  1602058540281221121   \n",
       "597065  1602038425011601408  1602058856703688705   \n",
       "\n",
       "                                                  op_text  \\\n",
       "13      I would love to have a sit down conversation w...   \n",
       "14      I would love to have a sit down conversation w...   \n",
       "15      I would love to have a sit down conversation w...   \n",
       "16      I would love to have a sit down conversation w...   \n",
       "17      I would love to have a sit down conversation w...   \n",
       "...                                                   ...   \n",
       "597047  bro's mad about fortnite skins not having any ...   \n",
       "597048  (4) being close & playful together - feeling s...   \n",
       "597051                Okok, I’ll try to watch 5 minutes 🤮   \n",
       "597059                                     An air fryer?    \n",
       "597065                            Do think that happened?   \n",
       "\n",
       "                                               reply_text  \n",
       "13      I plan to stay out of gunshot range of you, an...  \n",
       "14      Start with the families of the two people you ...  \n",
       "15      Cry me a river.\\nRittenhouse wasn't found \"\"in...  \n",
       "16      You brought an AR15 to a town and killed peopl...  \n",
       "17                                        You are a heroe  \n",
       "...                                                   ...  \n",
       "597047                           Y’know the drill homes.   \n",
       "597048  (5) Gat returns home after work - Wa smells pe...  \n",
       "597051        SCAM, Dont watch at all - 1 second is a hit  \n",
       "597059                           why does it have a mouth  \n",
       "597065  no no, of course but thats what Jesse appears ...  \n",
       "\n",
       "[322073 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move reply_text at the end\n",
    "column_to_move = df.pop(\"reply_text\")\n",
    "df.insert(len(df.columns), \"reply_text\", column_to_move)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5d5e327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['op_id', 'reply_id', 'op_text', 'reply_text', '__index_level_0__'],\n",
       "    num_rows: 322073\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ds = Dataset(pa.Table.from_pandas(df))\n",
    "filtered_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a050571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds = filtered_ds.remove_columns(\"__index_level_0__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38012015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE FINAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cacc9b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['op_id', 'reply_id', 'op_text', 'reply_text'],\n",
       "        num_rows: 322073\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_base = DatasetDict({'train': filtered_ds})\n",
    "dataset_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10da3fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['op_id', 'reply_id', 'op_text', 'reply_text'],\n",
       "        num_rows: 257658\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['op_id', 'reply_id', 'op_text', 'reply_text'],\n",
       "        num_rows: 64415\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset_base[\"train\"].train_test_split(train_size=0.8) # Train = 80%, test+validation = 20%\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56ecdb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['op_id', 'reply_id', 'op_text', 'reply_text'],\n",
       "        num_rows: 257658\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['op_id', 'reply_id', 'op_text', 'reply_text'],\n",
       "        num_rows: 51532\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['op_id', 'reply_id', 'op_text', 'reply_text'],\n",
       "        num_rows: 12883\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_validation_and_test = dataset.pop(\"test\").train_test_split(train_size=0.8) # validation=16%, test=4%\n",
    "dataset[\"validation\"] = dataset_validation_and_test.pop(\"train\")\n",
    "dataset[\"test\"] = dataset_validation_and_test.pop(\"test\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6570640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb3960e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at /home/mark/.cache/huggingface/hub/models--gpt2-large/snapshots/e5ab12c7d42b9e60a6025476a688aab2c5695189/vocab.json\n",
      "loading file merges.txt from cache at /home/mark/.cache/huggingface/hub/models--gpt2-large/snapshots/e5ab12c7d42b9e60a6025476a688aab2c5695189/merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /home/mark/.cache/huggingface/hub/models--gpt2-large/snapshots/e5ab12c7d42b9e60a6025476a688aab2c5695189/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2-large\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1280,\n",
      "  \"n_head\": 20,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 36,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Adding <|start|> to the vocabulary\n",
      "Adding <|end|> to the vocabulary\n",
      "Adding <|pad|> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load the GPT tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(finetuned_model_name, bos_token='<|start|>', eos_token='<|end|>', pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "781b9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_split(examples):\n",
    "    return tokenizer(\n",
    "        '<|start|>'+ examples[\"op_text\"] + \"{REPLY}\" + examples[\"reply_text\"] + '<|end|>',\n",
    "        truncation=True,\n",
    "        max_length= 250 # Tweet max = 280, 2 tweets + \"{REPLY}\" divided by about 2 when converted to tokens\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "232a1b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02294c5ad1e24609a9bb2e7fa2168b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/257658 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6069b1bcb5a474587b2bf73f616a30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51532 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf342ee36b84b1ea3ce8815fa78707c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12883 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_and_split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7fa991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b689316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RELOAD MODEL\n",
    "\n",
    "#configuration = GPT2Config.from_pretrained(model_dir, output_hidden_states=False)\n",
    "#model = GPT2LMHeadModel.from_pretrained(model_dir, config=configuration)\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "24b93e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b22500c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 1280)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = GPT2Config.from_pretrained(finetuned_model_name, output_hidden_states=False)\n",
    "model = GPT2LMHeadModel.from_pretrained(finetuned_model_name, config=configuration)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e18642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments,AutoModelWithLMHead\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    overwrite_output_dir=True, \n",
    "    num_train_epochs=3, \n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    eval_steps = 15000, \n",
    "    save_steps=15000,\n",
    "    warmup_steps=5000,\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\"\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2eab04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: op_text, reply_text, op_id, reply_id. If op_text, reply_text, op_id, reply_id are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "/home/mark/mambaforge/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 162351\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 121764\n",
      "  Number of trainable parameters = 774033920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121764' max='121764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121764/121764 10:47:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.181700</td>\n",
       "      <td>3.155565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>3.048600</td>\n",
       "      <td>2.998014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>2.467800</td>\n",
       "      <td>2.922980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>2.405100</td>\n",
       "      <td>2.852515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>2.401700</td>\n",
       "      <td>2.794200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.916800</td>\n",
       "      <td>2.859834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.838700</td>\n",
       "      <td>2.834723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.919000</td>\n",
       "      <td>2.808198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: op_text, reply_text, op_id, reply_id. If op_text, reply_text, op_id, reply_id are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18040\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./generate_replies_model_new/checkpoint-15000\n",
      "Configuration saved in ./generate_replies_model_new/checkpoint-15000/config.json\n",
      "Model weights saved in ./generate_replies_model_new/checkpoint-15000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: op_text, reply_text, op_id, reply_id. If op_text, reply_text, op_id, reply_id are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18040\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./generate_replies_model_new/checkpoint-30000\n",
      "Configuration saved in ./generate_replies_model_new/checkpoint-30000/config.json\n",
      "Model weights saved in ./generate_replies_model_new/checkpoint-30000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: op_text, reply_text, op_id, reply_id. If op_text, reply_text, op_id, reply_id are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18040\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./generate_replies_model_new/checkpoint-45000\n",
      "Configuration saved in ./generate_replies_model_new/checkpoint-45000/config.json\n",
      "Model weights saved in ./generate_replies_model_new/checkpoint-45000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: op_text, reply_text, op_id, reply_id. If op_text, reply_text, op_id, reply_id are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18040\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./generate_replies_model_new/checkpoint-60000\n",
      "Configuration saved in ./generate_replies_model_new/checkpoint-60000/config.json\n",
      "Model weights saved in ./generate_replies_model_new/checkpoint-60000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: op_text, reply_text, op_id, reply_id. If op_text, reply_text, op_id, reply_id are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18040\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./generate_replies_model_new/checkpoint-75000\n",
      "Configuration saved in ./generate_replies_model_new/checkpoint-75000/config.json\n",
      "Model weights saved in ./generate_replies_model_new/checkpoint-75000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: op_text, reply_text, op_id, reply_id. If op_text, reply_text, op_id, reply_id are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18040\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./generate_replies_model_new/checkpoint-90000\n",
      "Configuration saved in ./generate_replies_model_new/checkpoint-90000/config.json\n",
      "Model weights saved in ./generate_replies_model_new/checkpoint-90000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: op_text, reply_text, op_id, reply_id. If op_text, reply_text, op_id, reply_id are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18040\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./generate_replies_model_new/checkpoint-105000\n",
      "Configuration saved in ./generate_replies_model_new/checkpoint-105000/config.json\n",
      "Model weights saved in ./generate_replies_model_new/checkpoint-105000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: op_text, reply_text, op_id, reply_id. If op_text, reply_text, op_id, reply_id are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18040\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./generate_replies_model_new/checkpoint-120000\n",
      "Configuration saved in ./generate_replies_model_new/checkpoint-120000/config.json\n",
      "Model weights saved in ./generate_replies_model_new/checkpoint-120000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=121764, training_loss=2.508804728561035, metrics={'train_runtime': 38866.4321, 'train_samples_per_second': 12.531, 'train_steps_per_second': 3.133, 'total_flos': 2.476099275139584e+17, 'train_loss': 2.508804728561035, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed7d4cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./generate_replies_model_new\n",
      "Configuration saved in ./generate_replies_model_new/config.json\n",
      "Model weights saved in ./generate_replies_model_new/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "265015b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b66d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50260, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (32): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (33): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (34): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (35): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=50260, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00c0afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def generate_outputs(input_text, nb_seq):\n",
    "    text_to_generate = input_text + \"{REPLY}\"\n",
    "    \n",
    "    encoded_input = tokenizer.encode(text_to_generate)\n",
    "    generated_output = torch.tensor(encoded_input).unsqueeze(0).to(device)\n",
    "    \n",
    "    new_max_length = (max_token_length / 2) + len(encoded_input) # Limit the generated tweet to about 280 characters max\n",
    "    \n",
    "    outputs = model.generate(\n",
    "            generated_output, \n",
    "            do_sample=True,   \n",
    "            top_k=50, \n",
    "            max_length = new_max_length,\n",
    "            top_p=0.95, \n",
    "            num_return_sequences=nb_seq\n",
    "        )\n",
    "    return [tokenizer.decode(o, skip_special_tokens=True).split('{REPLY}')[1]  for o in outputs] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8865318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: I'm celebrating the Christmas season with my family and friends. My favorite holiday drink is orange sherbet. #ChristmasIsComing 🎄 🎄\r\n",
      "#happylife #LoveIsComing #HappyThanksgiving  \r\n",
      "🧠🤟🧠🤟🧠 🤟🤟🧠  \r\n",
      "#HAPPYTHANKSGIVING #ChristmasIsComing #HAPPYGULFDAY  \r\n",
      "🍂🎁🎄👸🏼🎄👸🏼🎄\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_to_reply_to = \"Christmas is coming soon. What are you going to do for the holidays?\" # Put a tweet to reply to here\n",
    "\n",
    "decoded_outputs = generate_outputs(tweet_to_reply_to, 1)\n",
    "\n",
    "for i, output in enumerate(decoded_outputs):\n",
    "    if len(output) > 1:\n",
    "        print(\"{}: {}\\n\\n\".format(i, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7ff3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
